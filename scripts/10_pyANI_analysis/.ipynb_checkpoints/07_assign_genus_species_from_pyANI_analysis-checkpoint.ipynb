{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b60cab",
   "metadata": {},
   "source": [
    "# Assigning genus and species IDs based on pyANI analysis run on each connected component"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dfea90",
   "metadata": {},
   "source": [
    "**Set Up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d57e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import dwave_networkx as dnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567f5877",
   "metadata": {},
   "source": [
    "**Loading data and prepartaion**\n",
    "Here we are:\n",
    "- loading the `pyani report` output, which contains information like run ID, and run name etc.\n",
    "- getting dictionary with run names keyed by run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa9aafc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(Path(\"~/Desktop/Kiepas_et_al_2023_MLST/data/pyani_analysis/connected_components/runs.tab\").expanduser(), sep='\\t', index_col=0)\n",
    "data.rename(columns = {'run ID':'run_ID', 'date run':'date_run'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "966d31e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_ID_name = data.set_index(\"run_ID\").to_dict()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef1b76",
   "metadata": {},
   "source": [
    "**Assigning species and genus ID**\n",
    "Here, we:\n",
    "- write a function that removes suffix provided in the pyANI matrices\n",
    "- get a function that will use provided dataframe to calculate MST, and remove edges between genomes if their thereshold is lower than the one provided. In case, where cliques are present it will keep removing the lowest weight until no cliques are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7d4a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffix(row, col):\n",
    "    \"\"\"Return accession number from 'FILE' column.\"\"\"\n",
    "\n",
    "    try:\n",
    "        new = ' '.join(row[col].split(':')[:-1])\n",
    "    except IndexError:\n",
    "        new = 'NA'\n",
    "\n",
    "    return new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7af91b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ANI_tax_ID(df, thereshold, attribute, ANI_ID):\n",
    "        \"\"\"Assign taxon IDs based on ANI analysis. \n",
    "        \n",
    "        :param df: dataframe with each row providing pyANI identity and coverage for a given parir of genomes\n",
    "        :param thereshold: thereshold at which genomes should be separated (num)\n",
    "        :param attribute: comparision type deciding which should be used to separate genomes identity or coverage\n",
    "        :param ANI_ID: current number of assigned IDs\n",
    "        \"\"\"\n",
    "        \n",
    "        #Generate NetworkX grah with identity and coverage as edge attibutes \n",
    "        G_comp=nx.from_pandas_edgelist(df, 'genome1', 'genome2', ['identity', 'coverage'])\n",
    "        \n",
    "        current_assignments = {} #Hold empty dictionary\n",
    "\n",
    "        ANI_ID = ANI_ID\n",
    "\n",
    "        #Remove edges if thereshold for a given attribute is lower \n",
    "        edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute] < thereshold]\n",
    "        G_comp.remove_edges_from(edges_to_remove)\n",
    "        \n",
    "        #Check if the components are clique, if not remove edges until clique is achived\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            while dnx.is_clique(G_comp, component) == False:\n",
    "                weights = sorted(list(set([attrs[attribute] for n1, n2, attrs in G_comp.edges(data=True) if n1 in component and n2 in component])))\n",
    "                edges_to_remove = [(n1,n2) for n1, n2, attrs in G_comp.edges(data=True) if attrs[attribute] < (weights)[1] and n1 in component and n2 in component]\n",
    "                G_comp.remove_edges_from(edges_to_remove)\n",
    "                weights.remove(weights[1])\n",
    "\n",
    "                components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "                for component in components:\n",
    "                    if dnx.is_clique(G_comp, component) == True:\n",
    "                        break\n",
    "        #Assign IDs\n",
    "        components = [_ for _ in list(nx.connected_components(G_comp))]\n",
    "        for component in components:\n",
    "            current_assignments.update({_:ANI_ID for _ in component})\n",
    "            ANI_ID += 1\n",
    "\n",
    "    \n",
    "                \n",
    "        return current_assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d52a9df",
   "metadata": {},
   "source": [
    "**Running functions**\n",
    "Here we:\n",
    "- generate dataframes for each pyANI run so that it can be taken by `assign_ANI_tax_ID` and assign IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e50c5c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_species_ID = 1\n",
    "current_genus_ID = 1\n",
    "genome_genus_ID = {}\n",
    "genome_species_ID = {}\n",
    "for run_ID, run_name in run_ID_name.items():\n",
    "    identity = pd.read_csv(Path(f\"~/Desktop/Kiepas_et_al_2023_MLST/data/pyani_analysis/connected_components_matrices/matrix_identity_{run_ID}.tab\").expanduser(), sep='\\t').rename(columns={'Unnamed: 0': 'genome1'})\n",
    "    coverage = pd.read_csv(Path(f\"~/Desktop/Kiepas_et_al_2023_MLST/data/pyani_analysis/connected_components_matrices/matrix_coverage_{run_ID}.tab\").expanduser(), sep='\\t').rename(columns={'Unnamed: 0': 'genome1'})\n",
    "                    #Melting data\n",
    "    identity_melt = pd.melt(identity, id_vars=['genome1'], value_vars=[_ for _ in identity if _ != 'genome1'], var_name='genome2', value_name='identity')\n",
    "    coverage_melt = pd.melt(coverage, id_vars=['genome1'], value_vars=[_ for _ in identity if _ != 'genome1'], var_name='genome2', value_name='coverage')\n",
    "    \n",
    "                    #Combine data\n",
    "    combined = pd.merge(identity_melt, coverage_melt,  how='left', left_on=['genome1', 'genome2'], right_on = ['genome1','genome2'])\n",
    "    combined = combined[combined['genome1'] != combined['genome2']] #Remove self-to-self comparisions\n",
    "                    #Remove duplicate comparisions and keep minimum coverage and average identity\n",
    "    combined[['genome1','genome2']] = np.sort(combined[['genome1','genome2']].to_numpy(),axis=1)\n",
    "    fixed = (combined.groupby(['genome1','genome2']).agg(identity = ('identity','mean'), coverage = ('coverage','min')).reset_index())\n",
    "    fixed[\"genome1\"] = fixed.apply(remove_suffix,col='genome1', axis=1)\n",
    "    fixed['genome2'] = fixed.apply(remove_suffix,col='genome2', axis=1)\n",
    "    fixed = fixed.round(2)\n",
    "\n",
    "                    #Getting Genus ID\n",
    "    coverage = assign_ANI_tax_ID(fixed, 0.50, 'coverage', current_genus_ID)\n",
    "    current_genus_ID += len(set(coverage.values()))\n",
    "    genome_genus_ID.update(coverage)\n",
    "                    #Getting Species ID\n",
    "    identity = assign_ANI_tax_ID(fixed, 0.945, 'identity', current_species_ID)\n",
    "    current_species_ID += len(set(identity.values()))\n",
    "    genome_species_ID.update(identity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d69ecf",
   "metadata": {},
   "source": [
    "Adding the information to `~/Desktop/Kiepas_et_al_2023_MLST/data/MLST_scheme_revision/Genomes_ST_info.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b2667ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(Path(\"~/Desktop/Kiepas_et_al_2023_MLST/data/MLST_scheme_revision/Genomes_ST_info.csv\").expanduser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a5a6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['pyani_genus_ID'] = data2['pyani_label'].map(genome_genus_ID).fillna(0)\n",
    "data2['pyani_species_ID'] = data2['pyani_label'].map(genome_species_ID).fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7134773f",
   "metadata": {},
   "source": [
    "Assign pyANI genus and species IDs to connected components which were not included in the pyANI analysis (eg. singlenton STs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7e97b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genus_ID_per_genome = data2.set_index('accession').to_dict()['pyani_genus_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "963ce8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_genus = int(max(genus_ID_per_genome.values()))\n",
    "for accession, genus_ID in genus_ID_per_genome.items():\n",
    "    if genus_ID == 0:\n",
    "        current_genus += 1\n",
    "        genus_ID_per_genome[accession] = current_genus\n",
    "    else:\n",
    "        genus_ID_per_genome[accession] = int(genus_ID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "400c05cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['pyani_genus_ID'] = data2['accession'].map(genus_ID_per_genome).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f1fe2172",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_ID_per_genome = data2.set_index('accession').to_dict()['pyani_species_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c81b902",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_species = int(max(species_ID_per_genome.values()))\n",
    "for accession, species_ID in species_ID_per_genome.items():\n",
    "    if species_ID == 0:\n",
    "        current_species += 1\n",
    "        species_ID_per_genome[accession] = current_species\n",
    "    else:\n",
    "        species_ID_per_genome[accession] = int(species_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4231b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['pyani_species_ID'] = data2['accession'].map(species_ID_per_genome).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "41e5d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.to_csv(Path(\"~/Desktop/Kiepas_et_al_2023_MLST/data/MLST_scheme_revision/Genomes_ST_info.csv\").expanduser(), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
